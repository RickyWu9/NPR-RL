{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ModelConfig.__init__() got an unexpected keyword argument 'torch_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelConfig\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConfig\n\u001b[1;32m----> 9\u001b[0m model_config \u001b[38;5;241m=\u001b[39m ModelConfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD://LLM//CodeT5\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     10\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m     11\u001b[0m data_config \u001b[38;5;241m=\u001b[39m DataConfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD://Study//NPR&RL//ProjectV1//assets//Train\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, is_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ModelConfig.__init__() got an unexpected keyword argument 'torch_dtype'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir, '..'))\n",
    "from model.model_config import ModelConfig\n",
    "from data.data_config import DataConfig\n",
    "\n",
    "model_config = ModelConfig(\"qwen\", \"D://LLM//CodeT5\", torch_dtype=torch.float32)\n",
    "model, tokenizer = model_config.load_model()\n",
    "data_config = DataConfig(\"D://Study//NPR&RL//ProjectV1//assets//Train\", tokenizer, is_test=True)\n",
    "dataset = data_config.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'bug_method', 'bug_line', 'fix_line', 'prompt', 'input_ids', 'target_ids', 'input_mask', 'target_mask'])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data.keys())\n",
    "input_ids = data[\"input_ids\"]\n",
    "input_mask = data[\"input_mask\"]\n",
    "target_ids = data[\"target_ids\"]\n",
    "target_mask = data[\"target_mask\"]\n",
    "\n",
    "print(input_ids.shape)\n",
    "print(input_mask.shape)\n",
    "print(target_ids.shape)\n",
    "print(target_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 32100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = model(input_ids, input_mask, target_ids, target_mask).logits\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "model = model.float()\n",
    "output = model.generate(\n",
    "        input_ids = data[\"input_ids\"], \n",
    "        attention_mask = data[\"input_ids\"].ne(tokenizer.pad_token_id),\n",
    "        do_sample=False,\n",
    "        top_p=1,\n",
    "        top_k=10,\n",
    "        temperature=1.5,\n",
    "        max_length=32,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "torch.Size([31, 32100])\n",
      "tensor([[ 1.0951e+01,  2.8392e+01,  2.7427e+00,  ...,  4.1671e+00,\n",
      "          4.0522e+00,  9.0531e+00],\n",
      "        [ 4.2390e+00,  8.5767e+00,  4.1810e+00,  ...,  7.3698e+00,\n",
      "          6.6297e+00,  2.8217e+01],\n",
      "        [ 9.5582e-03,  7.2327e+00,  2.6452e+00,  ...,  2.5483e+00,\n",
      "          2.7126e+00,  2.1610e+00],\n",
      "        ...,\n",
      "        [-1.3057e+00,  4.0206e+00,  7.8687e+00,  ...,  3.4302e+00,\n",
      "          6.5345e+00,  3.2062e-01],\n",
      "        [-1.1365e+00,  1.0944e+00,  7.5901e+00,  ...,  3.1522e+00,\n",
      "          6.5545e+00,  1.1913e-01],\n",
      "        [-1.0851e+00,  1.3962e+00,  6.9470e+00,  ...,  3.6295e+00,\n",
      "          6.4179e+00,  1.9753e-01]])\n",
      "-295.63360595703125\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "() { if (i.getpasswordstate()){puffer =; } else {(kpw) {\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(output.sequences.squeeze(0).shape)\n",
    "print(torch.stack(output.scores, dim=0).squeeze(1).shape)\n",
    "scores = torch.stack(output.scores, dim=0).squeeze(1)\n",
    "print(scores)\n",
    "logits = scores.softmax(dim=-1)\n",
    "token = output.sequences.squeeze(0)[:-1]\n",
    "token_logits = logits[torch.arange(token.shape[0]), token]\n",
    "log_logits = torch.log(token_logits).sum().item()\n",
    "print(log_logits)\n",
    "print(torch.isnan(token_logits).any())\n",
    "print(torch.isinf(token_logits).any())\n",
    "\n",
    "\n",
    "output_txt = tokenizer.decode(\n",
    "    token, skip_special_tokens=True\n",
    ")\n",
    "print(output_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
