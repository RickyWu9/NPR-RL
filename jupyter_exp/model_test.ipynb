{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded......\n",
      "Loading data......\n",
      "total number of data: 144641\n",
      "train number of data: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12289.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir, '..'))\n",
    "from model.model_config import ModelConfig\n",
    "from data.data_config import DataConfig\n",
    "\n",
    "model_config = ModelConfig(\"qwen25\", \"/home/wuyi/wy/NPR-RL/assets/model/qwen25_ins\")\n",
    "model, tokenizer = model_config.load_model()\n",
    "data_config = DataConfig(\"/home/wuyi/wy/NPR-RL/assets/Train\", model_config, is_test=True)\n",
    "dataset = data_config.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'bug_method', 'bug_line', 'fix_line'])\n",
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-35): 36 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=2048, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data.keys())\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logits = model(input_ids, input_mask, target_ids, target_mask).logits\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.float()\n",
    "output = model.generate(\n",
    "        input_ids = data[\"input_ids\"], \n",
    "        attention_mask = data[\"input_ids\"].ne(tokenizer.pad_token_id),\n",
    "        do_sample=False,\n",
    "        top_p=1,\n",
    "        top_k=10,\n",
    "        temperature=1.5,\n",
    "        max_length=32,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(output.sequences.squeeze(0).shape)\n",
    "print(torch.stack(output.scores, dim=0).squeeze(1).shape)\n",
    "scores = torch.stack(output.scores, dim=0).squeeze(1)\n",
    "print(scores)\n",
    "logits = scores.softmax(dim=-1)\n",
    "token = output.sequences.squeeze(0)[:-1]\n",
    "token_logits = logits[torch.arange(token.shape[0]), token]\n",
    "log_logits = torch.log(token_logits).sum().item()\n",
    "print(log_logits)\n",
    "print(torch.isnan(token_logits).any())\n",
    "print(torch.isinf(token_logits).any())\n",
    "\n",
    "\n",
    "output_txt = tokenizer.decode(\n",
    "    token, skip_special_tokens=True\n",
    ")\n",
    "print(output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12313', '21313', 'asdad']\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'typeof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_767724/1059611446.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'typeof' is not defined"
     ]
    }
   ],
   "source": [
    "a = [\"12313\", \"21313\"]\n",
    "a.append(\"asdad\")\n",
    "print(a)\n",
    "a = \"\\n\".join(a)\n",
    "print(1)\n",
    "print(typeof(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
